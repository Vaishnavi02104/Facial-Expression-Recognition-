# -*- coding: utf-8 -*-
"""fer_EfficientNet_pytorch.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18pyPESLm-JtPSIjS7nus1lkZbQpweU-d
"""

import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.transforms as transforms
import torchvision.datasets as datasets
import torchvision.models as models
from torch.utils.data import DataLoader
from google.colab import drive
import os
import shutil
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import classification_report, accuracy_score, roc_curve, auc, precision_recall_curve, average_precision_score

# Mount Google Drive
drive.mount('/content/drive')

# Source and destination paths
source_path = '/content/drive/MyDrive/Research_Vaish/DATASET'
destination_path = '/content/dataset'

# Remove existing destination directory
if os.path.exists(destination_path):
    shutil.rmtree(destination_path)

# Create directory and copy dataset
os.makedirs(destination_path, exist_ok=True)
shutil.copytree(source_path, destination_path, dirs_exist_ok=True)

data_dir = '/content/dataset'

transform1 = transforms.Compose([
    transforms.Resize(256),
    transforms.RandomCrop(224),
    transforms.RandomHorizontalFlip(),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                         std=[0.229, 0.224, 0.225])
])

transform2 = transforms.Compose([
    transforms.Resize((224, 224)),  # No random crop or flip
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                         std=[0.229, 0.224, 0.225])
])

# Load dataset
train_dataset = datasets.ImageFolder(root=os.path.join(data_dir, 'train'), transform=transform1)
val_dataset = datasets.ImageFolder(root=os.path.join(data_dir, 'test'), transform=transform2)

batch_size = 32

train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=8, pin_memory=True)
val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=8, pin_memory=True)

print(f"Number of images in train set: {len(train_dataset)}")
print(f"Number of images in test set: {len(val_dataset)}")

import torch.nn.functional as F
from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights

class EfficientNetWithFusion(nn.Module):
    def __init__(self, num_classes):
        super(EfficientNetWithFusion, self).__init__()
        base_model = efficientnet_b0(weights=EfficientNet_B0_Weights.DEFAULT)

        # Extract feature extractor blocks
        self.stem = base_model.features[0]  # First conv + norm
        self.block1 = base_model.features[1]  # Low-level features
        self.block2 = base_model.features[2]
        self.block3 = base_model.features[3]  # Mid-level
        self.block4 = base_model.features[4]
        self.block5 = base_model.features[5]  # High-level
        self.block6 = base_model.features[6]
        self.block7 = base_model.features[7]

        self.pool = nn.AdaptiveAvgPool2d(1)

        # Fusion + classification
        self.fusion_conv = nn.Conv2d(376, 128, kernel_size=1)  # fuse block7+3+1 channels
        self.fc = nn.Linear(128, num_classes)

    def forward(self, x):
        x = self.stem(x)
        f1 = self.block1(x)  # Output: [B, 24, H/2, W/2]
        f2 = self.block2(f1)
        f3 = self.block3(f2)  # Output: [B, 32, H/4, W/4]
        f4 = self.block4(f3)
        f5 = self.block5(f4)
        f6 = self.block6(f5)
        f7 = self.block7(f6)  # Output: [B, 320, H/32, W/32]

        # Upsample all to f3's resolution (mid-scale)
        f1_up = F.interpolate(f1, size=f3.shape[2:], mode='bilinear', align_corners=False)
        f3_up = f3
        f7_up = F.interpolate(f7, size=f3.shape[2:], mode='bilinear', align_corners=False)

        # Concatenate features
        fused = torch.cat([f1_up, f3_up, f7_up], dim=1)  # [B, (24+32+320), H/4, W/4]
        fused = self.fusion_conv(fused)  # Reduce channels

        pooled = self.pool(fused).view(fused.size(0), -1)
        out = self.fc(pooled)
        return out

# Load model with fusion
model = EfficientNetWithFusion(num_classes=len(train_dataset.classes))
device = 'cuda' if torch.cuda.is_available() else 'cpu'
model = model.to(device)

# Load EfficientNet model
model = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.DEFAULT)
num_features = model.classifier[1].in_features
model.classifier[1] = nn.Linear(num_features, len(train_dataset.classes))

device = 'cuda' if torch.cuda.is_available() else 'cpu'
model = model.to(device)

# Training function
def train_model(model, train_loader, val_loader, criterion, optimizer, epochs=20):
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    model.train()
    print(f"Using device: {device}")

    for epoch in range(epochs):
        running_loss = 0.0
        correct = 0
        total = 0

        model.train()
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            running_loss += loss.item()
            _, predicted = outputs.max(1)
            total += labels.size(0)
            correct += predicted.eq(labels).sum().item()
            torch.cuda.empty_cache()

        train_loss = running_loss / len(train_loader)
        train_acc = 100 * correct / total

        # Validation phase
        model.eval()
        val_loss = 0.0
        val_correct = 0
        val_total = 0
        with torch.no_grad():
            for val_images, val_labels in val_loader:
                val_images, val_labels = val_images.to(device), val_labels.to(device)
                val_outputs = model(val_images)
                val_loss += criterion(val_outputs, val_labels).item()
                _, val_predicted = val_outputs.max(1)
                val_total += val_labels.size(0)
                val_correct += val_predicted.eq(val_labels).sum().item()

        val_loss /= len(val_loader)
        val_acc = 100 * val_correct / val_total

        print(f"Epoch {epoch+1} - Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%")

    return model

# Loss and optimizer
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.0001)

# Train the model
model = train_model(model, train_loader, val_loader, criterion, optimizer, epochs=40)

# Save the model
torch.save(model.state_dict(), '/content0/drive/MyDrive/effici0entnet_facial_expression.pth')

# Loss and optimizer
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.0001)

# Train the model
model = train_model(model, train_loader, val_loader, criterion, optimizer, epochs=40)

# Save the model, correcting the path to '/content/drive/MyDrive/...'
torch.save(model.state_dict(), '/content/drive/MyDrive/efficientnet_facial_expression.pth')

'''# Loss and optimizer
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.000001)

# Train the model
model = train_model(model, train_loader, val_loader, criterion, optimizer, epochs=20)

# Save the model
torch.save(model.state_dict(), '/content/drive/MyDrive/efficientnet_facial_expression.pth')

# Evaluation function
def evaluate_model(model, val_loader):
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    model.eval()

    all_preds = []
    all_labels = []
    all_probs = []

    with torch.no_grad():
        for images, labels in val_loader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            probs = torch.softmax(outputs, dim=1)
            _, predicted = outputs.max(1)

            all_preds.extend(predicted.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())
            all_probs.extend(probs.cpu().numpy())

    all_labels = np.array(all_labels, dtype=int)
    all_probs = np.array(all_probs)

    print("Classification Report:")
    print(classification_report(all_labels, all_preds, target_names=val_dataset.classes))
    print("Accuracy:", accuracy_score(all_labels, all_preds))

    all_labels_one_hot = np.eye(len(val_dataset.classes))[all_labels]

    plt.figure(figsize=(8, 6))
    for i in range(len(val_dataset.classes)):
        fpr, tpr, _ = roc_curve(all_labels_one_hot[:, i], all_probs[:, i])
        roc_auc = auc(fpr, tpr)
        plt.plot(fpr, tpr, label=f'Class {val_dataset.classes[i]} (AUC = {roc_auc:.2f})')

    plt.plot([0, 1], [0, 1], 'k--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('ROC Curve')
    plt.legend()
    plt.show()

    plt.figure(figsize=(8, 6))
    for i in range(len(val_dataset.classes)):
        precision, recall, _ = precision_recall_curve(all_labels_one_hot[:, i], all_probs[:, i])
        pr_auc = average_precision_score(all_labels_one_hot[:, i], all_probs[:, i])
        plt.plot(recall, precision, label=f'Class {val_dataset.classes[i]} (AP = {pr_auc:.2f})')

    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend()
    plt.show()

evaluate_model(model, val_loader)

