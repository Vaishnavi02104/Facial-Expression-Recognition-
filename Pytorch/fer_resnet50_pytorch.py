# -*- coding: utf-8 -*-
"""fer_ResNet50_pytorch.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fv-p1ChvcT84qiqe3Ey8KnBpqfiHzq5e
"""

import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.transforms as transforms
import torchvision.datasets as datasets
import torchvision.models as models
from torch.utils.data import DataLoader
from google.colab import drive
import os
import shutil
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import classification_report, accuracy_score, roc_curve, auc, precision_recall_curve, average_precision_score

# Mount Google Drive
drive.mount('/content/drive')

# Source and destination paths
source_path = '/content/drive/MyDrive/Research_Vaish/DATASET'
destination_path = '/content/dataset'

# Remove existing destination directory
if os.path.exists(destination_path):
    shutil.rmtree(destination_path)

# Create directory and copy dataset
os.makedirs(destination_path, exist_ok=True)
shutil.copytree(source_path, destination_path, dirs_exist_ok=True)

data_dir = '/content/dataset'

# Define transformations
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

batch_size = 32

# Load dataset
train_dataset = datasets.ImageFolder(root=os.path.join(data_dir, 'train'), transform=transform)
val_dataset = datasets.ImageFolder(root=os.path.join(data_dir, 'test'), transform=transform)

train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=8, pin_memory=True)
val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=8, pin_memory=True)

print(f"Number of images in train set: {len(train_dataset)}")
print(f"Number of images in test set: {len(val_dataset)}")

# Load ResNet50 model
model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)
num_features = model.fc.in_features
model.fc = nn.Linear(num_features, len(train_dataset.classes))

device = 'cuda' if torch.cuda.is_available() else 'cpu'
model = model.to(device)

# Training function
def train_model(model, train_loader, val_loader, criterion, optimizer, epochs=20):
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    model.train()
    print(f"Using device: {device}")

    for epoch in range(epochs):
        running_loss = 0.0
        correct = 0
        total = 0

        model.train()
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            running_loss += loss.item()
            _, predicted = outputs.max(1)
            total += labels.size(0)
            correct += predicted.eq(labels).sum().item()
            torch.cuda.empty_cache()

        train_loss = running_loss / len(train_loader)
        train_acc = 100 * correct / total

        # Validation phase
        model.eval()
        val_loss = 0.0
        val_correct = 0
        val_total = 0
        with torch.no_grad():
            for val_images, val_labels in val_loader:
                val_images, val_labels = val_images.to(device), val_labels.to(device)
                val_outputs = model(val_images)
                val_loss += criterion(val_outputs, val_labels).item()
                _, val_predicted = val_outputs.max(1)
                val_total += val_labels.size(0)
                val_correct += val_predicted.eq(val_labels).sum().item()

        val_loss /= len(val_loader)
        val_acc = 100 * val_correct / val_total

        print(f"Epoch {epoch+1} - Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%")

    return model

# Loss and optimizer
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.0001)

# Train the model
model = train_model(model, train_loader, val_loader, criterion, optimizer, epochs=20)

# Save the model
torch.save(model.state_dict(), '/content/drive/MyDrive/resnet50_facial_expression.pth')

# Evaluation function
def evaluate_model(model, val_loader):
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    model.eval()

    all_preds = []
    all_labels = []
    all_probs = []

    with torch.no_grad():
        for images, labels in val_loader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            probs = torch.softmax(outputs, dim=1)
            _, predicted = outputs.max(1)

            all_preds.extend(predicted.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())
            all_probs.extend(probs.cpu().numpy())

    all_labels = np.array(all_labels, dtype=int)
    all_probs = np.array(all_probs)

    print("Classification Report:")
    print(classification_report(all_labels, all_preds, target_names=val_dataset.classes))
    print("Accuracy:", accuracy_score(all_labels, all_preds))

    all_labels_one_hot = np.eye(len(val_dataset.classes))[all_labels]

    plt.figure(figsize=(8, 6))
    for i in range(len(val_dataset.classes)):
        fpr, tpr, _ = roc_curve(all_labels_one_hot[:, i], all_probs[:, i])
        roc_auc = auc(fpr, tpr)
        plt.plot(fpr, tpr, label=f'Class {val_dataset.classes[i]} (AUC = {roc_auc:.2f})')

    plt.plot([0, 1], [0, 1], 'k--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('ROC Curve')
    plt.legend()
    plt.show()

    plt.figure(figsize=(8, 6))
    for i in range(len(val_dataset.classes)):
        precision, recall, _ = precision_recall_curve(all_labels_one_hot[:, i], all_probs[:, i])
        pr_auc = average_precision_score(all_labels_one_hot[:, i], all_probs[:, i])
        plt.plot(recall, precision, label=f'Class {val_dataset.classes[i]} (AP = {pr_auc:.2f})')

    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend()
    plt.show()

evaluate_model(model, val_loader)

